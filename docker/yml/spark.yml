# Cấu hình chung cho các service Spark
x-spark-common: &spark-common
    image: bitnami/spark:latest
    networks:
        - hdfs_network
        - spark_network
    environment:
        - SPARK_HOME=/opt/bitnami/spark
        - SPARK_CONF_DIR=/opt/bitnami/spark/conf
        - SPARK_LOG_DIR=/opt/bitnami/spark/logs
        - SPARK_PID_DIR=/opt/bitnami/spark/pids
        - SPARK_WORKER_DIR=/opt/bitnami/spark/work
        - SPARK_DAEMON_USER=daemon
        - SPARK_DAEMON_GROUP=daemon
        - SPARK_MASTER_PORT=7077
        - SPARK_MASTER_HOST=spark-master
    volumes:
        - ../../data_processing/spark/jobs:/opt/bitnami/spark/jobs
        - ../../data_processing/spark/common:/opt/bitnami/spark/common
        - ../../data_processing/spark/pipelines:/opt/bitnami/spark/pipelines
        # - ../../data_processing/spark/conf:/opt/bitnami/spark/conf
        # - ../../data_processing/spark/logs:/opt/bitnami/spark/logs

services:
    spark-master:
        <<: *spark-common
        container_name: spark-master
        environment:
            - SPARK_MODE=master
            - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
        ports:
            - '7077:7077'
            - '8181:8080'

    spark-worker-1:
        <<: *spark-common
        container_name: spark-worker1
        environment:
            - SPARK_MODE=worker
            - SPARK_MASTER_URL=spark://spark-master:7077
            - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
        depends_on:
            - spark-master

    spark-worker-2:
        <<: *spark-common
        container_name: spark-worker2
        environment:
            - SPARK_MODE=worker
            - SPARK_MASTER_URL=spark://spark-master:7077
            - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
        depends_on:
            - spark-master

    jupyter:
        build:
            context: ../../data_processing
            dockerfile: notebooks/Dockerfile
        container_name: jupyter
        ports:
            - '8888:8888'
        volumes:
            - ../../data_processing/notebooks:/home/jovyan/work
        networks:
            - hdfs_network
            - spark_network

    spark-processor:
        build:
            context: ../../data_processing/spark
            dockerfile: Dockerfile
        container_name: spark-processor
        image: spark-processor:latest
        networks:
            - hdfs_network
            - spark_network
        environment:
            - SPARK_MASTER_URL=spark://spark-master:7077
            - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
            - SPARK_DRIVER_MEMORY=2g
            - SPARK_EXECUTOR_MEMORY=2g
        volumes:
            - ../../data_processing/spark/jobs:/app/jobs
            - ../../data_processing/spark/common:/app/common
            - ../../data_processing/spark/pipelines:/app/pipelines
            - /var/run/docker.sock:/var/run/docker.sock
        depends_on:
            - spark-master
        restart: unless-stopped

networks:
    hdfs_network:
        external: true
        name: hdfs_network
    spark_network:
        name: spark_network
