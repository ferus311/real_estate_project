# Cấu hình chung cho các service Spark
x-spark-common: &spark-common
    image: bitnami/spark:3.4.1
    networks:
        - hdfs_network
        - spark_network
    volumes:
        - ../../data_processing/spark/jobs:/opt/bitnami/spark/jobs
        - ../../data_processing/spark/common:/opt/bitnami/spark/common
        - ../../data_processing/spark/pipelines:/opt/bitnami/spark/pipelines
        # - ../../data_processing/spark/conf:/opt/bitnami/spark/conf
        # - ../../data_processing/spark/logs:/opt/bitnami/spark/logs

services:
    spark-master:
        <<: *spark-common
        container_name: spark-master
        environment:
            - SPARK_MODE=master
            - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
        ports:
            - '7077:7077'
            - '8181:8080'

    spark-worker-1:
        <<: *spark-common
        container_name: spark-worker1
        environment:
            - SPARK_MODE=worker
            - SPARK_MASTER_URL=spark://spark-master:7077
            - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
        depends_on:
            - spark-master

    # spark-worker-2:
    #     <<: *spark-common
    #     container_name: spark-worker2
    #     environment:
    #         - SPARK_MODE=worker
    #         - SPARK_MASTER_URL=spark://spark-master:7077
    #         - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
    #     depends_on:
    #         - spark-master

    jupyter:
        build:
            context: ../../data_processing
            dockerfile: notebooks/Dockerfile
        container_name: jupyter
        ports:
            - '8888:8888'
        volumes:
            - ../../data_processing/notebooks:/home/jovyan/work
        networks:
            - hdfs_network
            - spark_network

    spark-processor:
        build:
            context: ../../data_processing/spark
            dockerfile: Dockerfile
        container_name: spark-processor
        image: spark-processor:latest
        networks:
            - hdfs_network
            - spark_network
        environment:
            # - SPARK_MODE=worker
            - SPARK_MASTER_URL=spark://spark-master:7077
            - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
            - SPARK_DRIVER_MEMORY=2g
            - SPARK_EXECUTOR_MEMORY=2g
        volumes:
            - ../../data_processing/spark/jobs:/app/jobs
            - ../../data_processing/spark/common:/app/common
            - ../../data_processing/spark/pipelines:/app/pipelines
            # Mount additional volumes for logs and data persistence
            - ../../data/spark_logs:/opt/bitnami/spark/logs
            - /var/run/docker.sock:/var/run/docker.sock
        depends_on:
            - spark-master
        restart: unless-stopped

networks:
    hdfs_network:
        external: true
        name: hdfs_network
    spark_network:
        name: spark_network
