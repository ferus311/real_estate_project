# üè† Quy Tr√¨nh X·ª≠ L√Ω D·ªØ Li·ªáu Training Model D·ª± ƒêo√°n Gi√° Nh√†

## üìã T·ªïng Quan

T√†i li·ªáu n√†y m√¥ t·∫£ chi ti·∫øt **quy tr√¨nh x·ª≠ l√Ω d·ªØ li·ªáu c·ª• th·ªÉ** ƒë·ªÉ training model d·ª± ƒëo√°n gi√° nh√† b·∫•t ƒë·ªông s·∫£n, bao g·ªìm t·ª´ Gold Data ƒë·∫øn Model ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán s·∫µn s√†ng prediction.

---

## üîÑ Lu·ªìng X·ª≠ L√Ω D·ªØ Li·ªáu Training

```
üìä Gold Data (HDFS)           üéØ NGU·ªíN D·ªÆ LI·ªÜU ƒê√É ƒê∆Ø·ª¢C L√ÄM S·∫†CH
       ‚Üì
üîç Data Quality Validation    üîç KI·ªÇM TRA CH·∫§T L∆Ø·ª¢NG & T√çNH TO√ÄN V·∫∏N
       ‚Üì
üîß Feature Engineering        üõ†Ô∏è T·∫†O C√ÅC FEATURES CHO ML
       ‚Üì
üìä Data Preparation          üìà CHU·∫®N B·ªä D·ªÆ LI·ªÜU CHO TRAINING
       ‚Üì
ü§ñ Model Training Pipeline   üéØ TRAINING MULTIPLE MODELS
       ‚Üì
üíæ Model Registry            üì¶ L∆ØU TR·ªÆ & PHI√äN B·∫¢N MODEL
       ‚Üì
üîÆ Production Deployment     üöÄ TRI·ªÇN KHAI S·∫¢N XU·∫§T
```

### üéØ Lu·ªìng D·ªØ Li·ªáu Chi Ti·∫øt

```
Raw Data ‚Üí Bronze ‚Üí Silver ‚Üí Gold ‚Üí ML Features ‚Üí Trained Models ‚Üí API Serving
                                  ‚Üë____________TRAINING SCOPE____________‚Üë
```

## üìä Gold Data - Ngu·ªìn D·ªØ Li·ªáu Training

### üóÇÔ∏è C·∫•u Tr√∫c D·ªØ Li·ªáu Gold

```
/data/realestate/processed/gold/unified/
‚îú‚îÄ‚îÄ apartment/               # üè¢ CƒÉn h·ªô
‚îÇ   ‚îî‚îÄ‚îÄ 2025/01/06/
‚îÇ       ‚îî‚îÄ‚îÄ unified_apartment_20250106.parquet
‚îú‚îÄ‚îÄ house/                   # üè† Nh√† ph·ªë
‚îÇ   ‚îî‚îÄ‚îÄ 2025/01/06/
‚îÇ       ‚îî‚îÄ‚îÄ unified_house_20250106.parquet
‚îú‚îÄ‚îÄ land/                    # üåç ƒê·∫•t n·ªÅn
‚îÇ   ‚îî‚îÄ‚îÄ 2025/01/06/
‚îÇ       ‚îî‚îÄ‚îÄ unified_land_20250106.parquet
‚îî‚îÄ‚îÄ commercial/              # üè™ Th∆∞∆°ng m·∫°i
    ‚îî‚îÄ‚îÄ 2025/01/06/
        ‚îî‚îÄ‚îÄ unified_commercial_20250106.parquet
```

### üìã Schema D·ªØ Li·ªáu Gold

```python
Gold Data Schema (Ready for ML):
‚îú‚îÄ‚îÄ id: string                    # Unique property ID
‚îú‚îÄ‚îÄ price: long                   # Target variable (VND)
‚îú‚îÄ‚îÄ area: double                  # Di·ªán t√≠ch (m¬≤)
‚îú‚îÄ‚îÄ bedroom: double               # S·ªë ph√≤ng ng·ªß
‚îú‚îÄ‚îÄ bathroom: double              # S·ªë ph√≤ng t·∫Øm
‚îú‚îÄ‚îÄ floor_count: double           # S·ªë t·∫ßng
‚îú‚îÄ‚îÄ facade_width: double          # M·∫∑t ti·ªÅn (m)
‚îú‚îÄ‚îÄ road_width: double            # ƒê∆∞·ªùng v√†o (m)
‚îú‚îÄ‚îÄ city: string                  # Th√†nh ph·ªë
‚îú‚îÄ‚îÄ district: string              # Qu·∫≠n/Huy·ªán
‚îú‚îÄ‚îÄ ward: string                  # Ph∆∞·ªùng/X√£
‚îú‚îÄ‚îÄ address: string               # ƒê·ªãa ch·ªâ chi ti·∫øt
‚îú‚îÄ‚îÄ latitude: double              # T·ªça ƒë·ªô GPS
‚îú‚îÄ‚îÄ longitude: double             # T·ªça ƒë·ªô GPS
‚îú‚îÄ‚îÄ property_type: string         # Lo·∫°i BDS
‚îú‚îÄ‚îÄ legal_status: string          # T√¨nh tr·∫°ng ph√°p l√Ω
‚îú‚îÄ‚îÄ interior_status: string       # T√¨nh tr·∫°ng n·ªôi th·∫•t
‚îú‚îÄ‚îÄ house_direction: string       # H∆∞·ªõng nh√†
‚îú‚îÄ‚îÄ description: string           # M√¥ t·∫£ chi ti·∫øt
‚îú‚îÄ‚îÄ crawl_date: date             # Ng√†y thu th·∫≠p
‚îú‚îÄ‚îÄ source: string               # Ngu·ªìn d·ªØ li·ªáu
‚îú‚îÄ‚îÄ url: string                  # Link g·ªëc
‚îî‚îÄ‚îÄ quality_score: double        # ƒêi·ªÉm ch·∫•t l∆∞·ª£ng d·ªØ li·ªáu
```

---

## üîç B∆∞·ªõc 1: Data Quality Validation

### üéØ M·ª•c ƒê√≠ch

Ki·ªÉm tra ch·∫•t l∆∞·ª£ng v√† t√≠nh to√†n v·∫πn c·ªßa Gold Data tr∆∞·ªõc khi training

### üîß Quy Tr√¨nh Validation

```python
# File: data_processing/spark/jobs/enrichment/ml_feature_engineering.py
def validate_training_data(df: DataFrame) -> Dict[str, Any]:
    """
    Validates data quality for ML training
    """
    validation_results = {
        'total_records': df.count(),
        'missing_target': df.filter(col('price').isNull()).count(),
        'missing_features': {},
        'outliers': {},
        'quality_flags': {}
    }

    # 1. Target Variable Validation
    price_stats = df.select(
        count('price').alias('valid_prices'),
        min('price').alias('min_price'),
        max('price').alias('max_price'),
        avg('price').alias('avg_price')
    ).collect()[0]

    # 2. Feature Completeness Check
    critical_features = ['area', 'city', 'district', 'property_type']
    for feature in critical_features:
        missing_count = df.filter(col(feature).isNull()).count()
        validation_results['missing_features'][feature] = missing_count

    # 3. Outlier Detection
    # Price outliers (beyond 3 standard deviations)
    price_mean = df.select(avg('price')).collect()[0][0]
    price_std = df.select(stddev('price')).collect()[0][0]
    outlier_threshold = price_mean + (3 * price_std)

    outliers = df.filter(col('price') > outlier_threshold).count()
    validation_results['outliers']['price'] = outliers

    return validation_results
```

### üìä Quality Metrics

| Metric           | Threshold | Action      |
| ---------------- | --------- | ----------- |
| Missing Price    | < 5%      | ‚úÖ Continue |
| Missing Area     | < 10%     | ‚úÖ Continue |
| Missing Location | < 15%     | ‚ö†Ô∏è Warning  |
| Price Outliers   | < 2%      | ‚úÖ Continue |
| Data Freshness   | < 7 days  | ‚úÖ Continue |

---

## üîß B∆∞·ªõc 2: Feature Engineering Pipeline

### üéØ M·ª•c ƒê√≠ch

Chuy·ªÉn ƒë·ªïi Gold Data th√†nh **60+ ML Features** phong ph√∫ v√† c√≥ √Ω nghƒ©a

### üìà Categories Features ƒë∆∞·ª£c t·∫°o

#### 1. **Basic Features** (15 features)

```python
# Numeric transformations
price_log = log(price + 1)                    # Log transformation
area_log = log(area + 1)                      # Log transformation
price_per_sqm = price / area                  # Gi√° tr√™n m¬≤
price_per_bedroom = price / bedroom           # Gi√° tr√™n ph√≤ng ng·ªß
bedroom_bathroom_ratio = bedroom / bathroom   # T·ª∑ l·ªá ph√≤ng

# Boolean features
has_elevator = facade_width > 8               # C√≥ thang m√°y
is_corner_lot = road_width > 6               # ƒê·∫•t g√≥c
is_large_property = area > 200               # BDS l·ªõn
```

#### 2. **Geospatial Features** (8 features)

```python
# Location encoding
city_encoded = StringIndexer.fit('city')
district_encoded = StringIndexer.fit('district')
province_normalized = standardize_province_names()

# Distance calculations (if coordinates available)
distance_to_center = calculate_distance_to_city_center()
proximity_to_main_road = estimate_road_proximity()
```

#### 3. **Market Features** (12 features)

```python
# Market analysis per location
avg_price_by_location = Window.partitionBy('city', 'district').avg('price')
price_deviation_from_market = (price - avg_price_by_location) / avg_price_by_location
price_percentile_in_location = percent_rank().over(location_window)

# Supply density
supply_density = count().over(location_window)
price_volatility = stddev('price').over(location_window)
```

#### 4. **Temporal Features** (4 features)

```python
# Time components
year = year('crawl_date')
month = month('crawl_date')
quarter = quarter('crawl_date')
season = when(month.isin(12,1,2), 'winter')
         .when(month.isin(3,4,5), 'spring')
         .when(month.isin(6,7,8), 'summer')
         .otherwise('autumn')

# Recency
days_since_crawl = datediff(current_date(), 'crawl_date')
```

#### 5. **Text Features** (6 features)

```python
# Description analysis
description_length = length('description')
description_word_count = size(split('description', ' '))
has_balcony = description.contains('ban c√¥ng|balcony')
has_parking = description.contains('ch·ªó ƒë·ªó xe|garage|parking')
has_garden = description.contains('s√¢n v∆∞·ªùn|garden')
description_richness = description_length / 100  # Quality metric
```

#### 6. **Interaction Features** (15 features)

```python
# Feature combinations
area_location_interaction = area * city_encoded
price_segment = when(price_percentile_in_location < 0.33, 'low')
           .when(price_percentile_in_location < 0.67, 'medium')
           .otherwise('high')

# Property value indicators
luxury_indicator = (price_per_sqm > luxury_threshold) & (area > 150)
investment_potential = price_deviation_from_market < -0.2  # Undervalued
```

### üîÑ Feature Engineering Flow

```python
# File: data_processing/spark/jobs/enrichment/ml_feature_engineering.py
def run_feature_engineering_pipeline(spark, input_date, property_type):
    """
    Complete feature engineering pipeline
    """
    # 1. Load validated Gold data
    gold_path = f"/data/realestate/processed/gold/unified/{property_type}"
    gold_df = spark.read.parquet(f"{gold_path}/{input_date}")

    # 2. Create basic features
    features_df = create_basic_features(gold_df)

    # 3. Add geospatial features
    features_df = add_geospatial_features(features_df)

    # 4. Add market features
    features_df = add_market_features(features_df)

    # 5. Add temporal features
    features_df = add_temporal_features(features_df)

    # 6. Add text features
    features_df = add_text_features(features_df)

    # 7. Add interaction features
    features_df = add_interaction_features(features_df)

    # 8. Save to Feature Store
    output_path = f"/data/realestate/ml/features/{property_type}/{input_date}"
    features_df.write.mode('overwrite').parquet(output_path)

    return features_df
```

### üìä Feature Store Output

```
/data/realestate/ml/features/{property_type}/{date}/
‚îú‚îÄ‚îÄ features.parquet              # Processed features (60+ columns)
‚îú‚îÄ‚îÄ feature_metadata.json        # Feature definitions & statistics
‚îî‚îÄ‚îÄ feature_importance.json      # Feature importance from previous runs
```

‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ xgboost/
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ lightgbm/
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ catboost/
‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ ensemble/
‚îÇ ‚îî‚îÄ‚îÄ predictions/ # Prediction results
‚îî‚îÄ‚îÄ üìÅ analytics/ # Analysis outputs
‚îú‚îÄ‚îÄ model_performance/
‚îú‚îÄ‚îÄ feature_importance/
‚îî‚îÄ‚îÄ market_insights/

````

### üìÖ Ch√≠nh S√°ch L∆∞u Tr·ªØ D·ªØ Li·ªáu

| **Lo·∫°i D·ªØ Li·ªáu** | **Retention Period** | **Partitioning** | **M·ª•c ƒê√≠ch** |
|-------------------|---------------------|------------------|--------------|
| ü•â **Bronze** | 7 ng√†y | `yyyy/mm/dd` | Raw data temporary storage |
| ü•à **Silver** | 30 ng√†y | `yyyy/mm/dd` | Cleaned data for analysis |
| ü•á **Gold** | 90 ng√†y | `property_type/yyyy/mm/dd` | Business-ready data |
| üîß **ML Features** | 60 ng√†y | `property_type/yyyy-mm-dd` | Training data |
| ü§ñ **Models** | 180 ng√†y | `model_name/version/` | Model artifacts |
| üìä **Predictions** | 30 ng√†y | `yyyy/mm/dd/property_type` | Inference results |

### üîÑ Data Lifecycle Management

```python
# Daily Cleanup Process
def cleanup_old_data():
    """
    X√≥a d·ªØ li·ªáu c≈© theo ch√≠nh s√°ch retention
    Ch·∫°y h√†ng ng√†y l√∫c 2:00 AM
    """
    # Bronze: X√≥a > 7 ng√†y
    remove_files_older_than("/data/realestate/processed/bronze", days=7)

    # Silver: X√≥a > 30 ng√†y
    remove_files_older_than("/data/realestate/processed/silver", days=30)

    # Gold: X√≥a > 90 ng√†y
    remove_files_older_than("/data/realestate/processed/gold", days=90)

    # ML Features: X√≥a > 60 ng√†y
    remove_files_older_than("/data/realestate/ml/features", days=60)

    # Models: Gi·ªØ l·∫°i 3 models t·ªët nh·∫•t, x√≥a models > 180 ng√†y
    cleanup_model_registry(keep_best=3, max_age_days=180)
````

---

## üîß Logic X·ª≠ L√Ω D·ªØ Li·ªáu M·ªói L·∫ßn Ch·∫°y

### üïí Scheduling Strategy

| **Frequency** | **Schedule**        | **Scope**       | **Purpose**                      |
| ------------- | ------------------- | --------------- | -------------------------------- |
| **Daily**     | 06:00 AM            | Incremental     | Training v·ªõi data m·ªõi trong 24h  |
| **Weekly**    | Sunday 02:00 AM     | Full Retraining | Retrain to√†n b·ªô v·ªõi data 30 ng√†y |
| **Monthly**   | 1st Sunday 01:00 AM | Model Refresh   | Evaluation v√† model selection    |

### üìã Daily Processing Logic

```python
def daily_ml_workflow(execution_date):
    """
    Logic x·ª≠ l√Ω h√†ng ng√†y cho ML pipeline

    Input: execution_date (yyyy-mm-dd)
    Output: Updated models v√† predictions
    """

    # 1Ô∏è‚É£ DATA VALIDATION
    data_quality_check = check_gold_data_quality(execution_date)
    if not data_quality_check.is_valid:
        raise ValueError("Data quality check failed")

    # 2Ô∏è‚É£ FEATURE ENGINEERING
    features_df = create_ml_features(
        gold_data_path=f"/data/realestate/processed/gold/unified/{property_type}/{execution_date}/",
        lookback_days=30,  # S·ª≠ d·ª•ng data 30 ng√†y g·∫ßn nh·∫•t
        feature_config=FEATURE_CONFIG
    )

    # 3Ô∏è‚É£ INCREMENTAL TRAINING
    for property_type in ['apartment', 'house', 'land']:
        updated_model = incremental_training(
            property_type=property_type,
            new_features=features_df,
            base_model_path=f"/data/realestate/ml/models/current/{property_type}/",
            learning_rate=0.1
        )

        # 4Ô∏è‚É£ MODEL VALIDATION
        validation_results = validate_model_performance(
            model=updated_model,
            validation_data=features_df.sample(0.2),
            metrics=['mae', 'rmse', 'mape']
        )

        # 5Ô∏è‚É£ MODEL DEPLOYMENT (n·∫øu performance t·ªët h∆°n)
        if validation_results.mae < current_best_mae:
            deploy_model_to_registry(
                model=updated_model,
                property_type=property_type,
                version=f"daily_{execution_date}",
                metrics=validation_results
            )

    # 6Ô∏è‚É£ PREDICTION GENERATION
    generate_daily_predictions(execution_date)

    # 7Ô∏è‚É£ PERFORMANCE MONITORING
    log_model_performance_metrics(execution_date)
```

### üìä Data Flow trong m·ªói l·∫ßn ch·∫°y

```
üåÖ B·∫Øt ƒë·∫ßu (06:00 AM)
    ‚Üì
üìä 1. Check Gold Data (Last 24h)
    ‚îú‚îÄ ‚úÖ Volume: Min 100 records/property_type
    ‚îú‚îÄ ‚úÖ Quality: 95% complete records
    ‚îî‚îÄ ‚úÖ Freshness: Data within 24h
    ‚Üì
üîß 2. Feature Engineering (30 min)
    ‚îú‚îÄ Load Gold data (30 days window)
    ‚îú‚îÄ Apply feature transformations (60+ features)
    ‚îú‚îÄ Create time-based features
    ‚îî‚îÄ Save to /ml/features/{property_type}/{date}/
    ‚Üì
ü§ñ 3. Incremental Training (60 min)
    ‚îú‚îÄ Load current best models
    ‚îú‚îÄ Train with new features
    ‚îú‚îÄ Validate performance
    ‚îî‚îÄ Update if improved
    ‚Üì
üîÆ 4. Generate Predictions (15 min)
    ‚îú‚îÄ Predict for new listings
    ‚îú‚îÄ Update market insights
    ‚îî‚îÄ Cache to Redis
    ‚Üì
üìà 5. Performance Monitoring (5 min)
    ‚îú‚îÄ Log metrics to MLflow
    ‚îú‚îÄ Generate alerts if needed
    ‚îî‚îÄ Update dashboards
    ‚Üì
üéØ Ho√†n th√†nh (08:00 AM)
```

---

## üéØ Chi·∫øn L∆∞·ª£c Training v√† L∆∞u Tr·ªØ Best Models

### üèÜ Model Selection Strategy

H·ªá th·ªëng l∆∞u tr·ªØ **3 models t·ªët nh·∫•t** cho m·ªói lo·∫°i b·∫•t ƒë·ªông s·∫£n:

```python
BEST_MODELS_CONFIG = {
    "selection_criteria": {
        "primary_metric": "mae",          # Mean Absolute Error
        "secondary_metrics": ["rmse", "mape", "r2"],
        "business_metrics": ["prediction_accuracy", "market_coverage"]
    },
    "model_types": {
        "ensemble": {"weight": 0.4, "priority": 1},    # ∆Øu ti√™n cao nh·∫•t
        "xgboost": {"weight": 0.25, "priority": 2},
        "lightgbm": {"weight": 0.25, "priority": 3},
        "catboost": {"weight": 0.1, "priority": 4}
    },
    "storage_strategy": {
        "keep_best": 3,                   # Gi·ªØ 3 models t·ªët nh·∫•t
        "archive_period": 180,            # Archive after 180 days
        "backup_frequency": "weekly"      # Weekly backups
    }
}
```

### üì¶ Model Registry Structure

```
/data/realestate/ml/models/
‚îú‚îÄ‚îÄ üìÅ current/                    # Models ƒëang s·ª≠ d·ª•ng
‚îÇ   ‚îú‚îÄ‚îÄ apartment/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ best_model_1/         # MAE: 0.085 (Ensemble)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ best_model_2/         # MAE: 0.092 (XGBoost)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ best_model_3/         # MAE: 0.098 (LightGBM)
‚îÇ   ‚îú‚îÄ‚îÄ house/
‚îÇ   ‚îî‚îÄ‚îÄ land/
‚îú‚îÄ‚îÄ üìÅ archive/                    # Models c≈©
‚îÇ   ‚îú‚îÄ‚îÄ 2024-01/
‚îÇ   ‚îú‚îÄ‚îÄ 2024-02/
‚îÇ   ‚îî‚îÄ‚îÄ 2024-03/
‚îî‚îÄ‚îÄ üìÅ experiments/               # Experimental models
    ‚îú‚îÄ‚îÄ hyperparameter_tuning/
    ‚îú‚îÄ‚îÄ feature_selection/
    ‚îî‚îÄ‚îÄ architecture_tests/
```

### üîÑ Model Update Process

```python
class ModelRegistryManager:
    """
    Qu·∫£n l√Ω registry v√† deployment c·ªßa models
    """

    def evaluate_and_update_best_models(self, new_model, property_type):
        """
        ƒê√°nh gi√° model m·ªõi v√† c·∫≠p nh·∫≠t top 3 n·∫øu c·∫ßn
        """
        current_best_models = self.load_current_best_models(property_type)

        # Evaluate new model
        new_model_metrics = self.evaluate_model(new_model)

        # Compare with current best
        all_models = current_best_models + [new_model]
        ranked_models = self.rank_models_by_performance(all_models)

        # Keep top 3
        new_best_models = ranked_models[:3]

        # Update registry if changed
        if new_best_models != current_best_models:
            self.update_model_registry(property_type, new_best_models)
            self.send_notification(f"Best models updated for {property_type}")

    def deploy_model(self, model_id, property_type, deployment_type="blue_green"):
        """
        Deploy model v·ªõi strategy blue-green
        """
        if deployment_type == "blue_green":
            # Deploy to staging environment first
            self.deploy_to_staging(model_id, property_type)

            # Run validation tests
            validation_results = self.run_deployment_validation(model_id)

            if validation_results["success"]:
                # Switch traffic from blue to green
                self.switch_traffic(model_id, property_type)
                self.log_deployment_success(model_id)
            else:
                self.rollback_deployment(model_id, property_type)
```

---

## üîÑ B∆∞·ªõc 3: Data Preparation (Chu·∫©n B·ªã D·ªØ Li·ªáu Training)

### üìä Train/Validation/Test Split Strategy

```python
def create_temporal_splits(gold_data, feature_data, config):
    """
    Chia d·ªØ li·ªáu theo th·ªùi gian ƒë·ªÉ tr√°nh data leakage
    """
    # Sort by listing_date ƒë·ªÉ ƒë·∫£m b·∫£o temporal order
    combined_data = gold_data.join(feature_data, ["listing_id"], "inner") \
                            .orderBy("listing_date")

    # Calculate split dates
    total_records = combined_data.count()
    train_end_date = "2024-01-31"     # 70% data (14 th√°ng ƒë·∫ßu)
    val_end_date = "2024-03-31"       # 15% data (2 th√°ng)
    # Test data: 2024-04-01 tr·ªü ƒëi     # 15% data (1.5 th√°ng)

    # Create splits
    train_data = combined_data.filter(f"listing_date <= '{train_end_date}'")
    val_data = combined_data.filter(f"listing_date > '{train_end_date}' AND listing_date <= '{val_end_date}'")
    test_data = combined_data.filter(f"listing_date > '{val_end_date}'")

    print(f"üìä Data Split Summary:")
    print(f"   Training: {train_data.count():,} records ({train_data.count()/total_records*100:.1f}%)")
    print(f"   Validation: {val_data.count():,} records ({val_data.count()/total_records*100:.1f}%)")
    print(f"   Test: {test_data.count():,} records ({test_data.count()/total_records*100:.1f}%)")

    return train_data, val_data, test_data
```

### üè† Property Type Stratification

```python
def stratify_by_property_type(train_data, val_data, test_data):
    """
    ƒê·∫£m b·∫£o distribution ƒë·ªìng ƒë·ªÅu cho t·ª´ng lo·∫°i BDS
    """
    property_distribution = {
        "apartment": {"train": 0.65, "val": 0.20, "test": 0.15},
        "house": {"train": 0.70, "val": 0.15, "test": 0.15},
        "land": {"train": 0.75, "val": 0.15, "test": 0.10}  # √çt data h∆°n cho land
    }

    stratified_datasets = {}

    for property_type in ["apartment", "house", "land"]:
        # Filter by property type
        train_prop = train_data.filter(f"property_type = '{property_type}'")
        val_prop = val_data.filter(f"property_type = '{property_type}'")
        test_prop = test_data.filter(f"property_type = '{property_type}'")

        # Apply additional stratification if needed
        if property_type == "apartment":
            # Stratify by district for apartments (urban distribution)
            train_prop = stratify_by_district(train_prop, min_samples_per_district=100)
            val_prop = stratify_by_district(val_prop, min_samples_per_district=20)

        stratified_datasets[property_type] = {
            "train": train_prop,
            "val": val_prop,
            "test": test_prop
        }

        print(f"üè† {property_type.title()} Distribution:")
        print(f"   Train: {train_prop.count():,}")
        print(f"   Val: {val_prop.count():,}")
        print(f"   Test: {test_prop.count():,}")

    return stratified_datasets
```

### üßπ Data Preprocessing Pipeline

```python
class DataPreprocessor:
    """
    Preprocessing pipeline cho training data
    """

    def __init__(self, config):
        self.config = config
        self.scalers = {}
        self.encoders = {}
        self.feature_selectors = {}

    def preprocess_features(self, train_data, val_data, test_data, property_type):
        """
        Apply full preprocessing pipeline
        """
        print(f"üßπ Preprocessing features for {property_type}...")

        # 1. Handle missing values
        train_clean = self.handle_missing_values(train_data, property_type, fit=True)
        val_clean = self.handle_missing_values(val_data, property_type, fit=False)
        test_clean = self.handle_missing_values(test_data, property_type, fit=False)

        # 2. Feature scaling
        train_scaled = self.scale_numerical_features(train_clean, property_type, fit=True)
        val_scaled = self.scale_numerical_features(val_clean, property_type, fit=False)
        test_scaled = self.scale_numerical_features(test_clean, property_type, fit=False)

        # 3. Categorical encoding
        train_encoded = self.encode_categorical_features(train_scaled, property_type, fit=True)
        val_encoded = self.encode_categorical_features(val_scaled, property_type, fit=False)
        test_encoded = self.encode_categorical_features(test_scaled, property_type, fit=False)

        # 4. Feature selection
        selected_features = self.select_features(train_encoded, property_type, fit=True)
        train_final = train_encoded.select(selected_features)
        val_final = val_encoded.select(selected_features)
        test_final = test_encoded.select(selected_features)

        return train_final, val_final, test_final

    def handle_missing_values(self, data, property_type, fit=False):
        """
        X·ª≠ l√Ω missing values v·ªõi strategy kh√°c nhau cho t·ª´ng feature type
        """
        missing_strategies = {
            # Numerical features
            "area": "median",           # Di·ªán t√≠ch ‚Üí median theo district
            "price_per_sqm": "median",  # Gi√°/m2 ‚Üí median theo district
            "age": "mean",              # Tu·ªïi nh√† ‚Üí mean
            "distance_*": "median",     # Kho·∫£ng c√°ch ‚Üí median

            # Categorical features
            "legal_document": "mode",   # Gi·∫•y t·ªù ‚Üí mode
            "interior": "unknown",      # N·ªôi th·∫•t ‚Üí "unknown"
            "orientation": "unknown",   # H∆∞·ªõng nh√† ‚Üí "unknown"

            # Boolean features
            "has_*": False,            # Has features ‚Üí False
            "is_*": False,             # Is features ‚Üí False
        }

        # Apply imputation
        for feature, strategy in missing_strategies.items():
            if "*" in feature:
                # Handle wildcard patterns
                matching_cols = [col for col in data.columns if feature.replace("*", "") in col]
                for col in matching_cols:
                    data = self.impute_column(data, col, strategy, property_type, fit)
            else:
                data = self.impute_column(data, feature, strategy, property_type, fit)

        return data

    def scale_numerical_features(self, data, property_type, fit=False):
        """
        Scale numerical features using RobustScaler
        """
        numerical_features = [
            "area", "price_per_sqm", "age", "floor", "bedrooms", "bathrooms",
            "distance_to_center", "distance_to_metro", "distance_to_school",
            "district_avg_price", "market_velocity", "listing_frequency",
            "temporal_price_trend", "seasonal_factor"
        ]

        scaler_key = f"{property_type}_numerical"

        if fit:
            # Fit scaler on training data
            from sklearn.preprocessing import RobustScaler
            self.scalers[scaler_key] = RobustScaler()

            # Convert to pandas for fitting
            train_pandas = data.select(numerical_features).toPandas()
            self.scalers[scaler_key].fit(train_pandas)

        # Transform data
        pandas_data = data.select(numerical_features).toPandas()
        scaled_data = self.scalers[scaler_key].transform(pandas_data)

        # Convert back to Spark DataFrame
        scaled_df = spark.createDataFrame(
            pd.DataFrame(scaled_data, columns=numerical_features)
        )

        # Join with non-numerical features
        non_numerical_cols = [col for col in data.columns if col not in numerical_features]
        non_numerical_data = data.select(non_numerical_cols)

        return non_numerical_data.join(scaled_df, on=["listing_id"])
```

---

## üöÄ B∆∞·ªõc 4: Model Training Pipeline (Pipeline Training Models)

### üéØ Multi-Model Training Strategy

```python
class ModelTrainingPipeline:
    """
    Pipeline training multiple models song song
    """

    def __init__(self, config):
        self.config = config
        self.models = self.initialize_models()
        self.hyperparameter_grids = self.setup_hyperparameter_grids()

    def train_all_models(self, train_data, val_data, property_type):
        """
        Train t·∫•t c·∫£ models cho m·ªôt property type
        """
        print(f"üöÄ Training models for {property_type}...")

        trained_models = {}
        training_history = {}

        # Train base models
        for model_name in ["xgboost", "lightgbm", "catboost", "random_forest"]:
            print(f"   üî• Training {model_name}...")

            # Hyperparameter tuning
            best_params = self.hyperparameter_tuning(
                model_name, train_data, val_data, property_type
            )

            # Train final model with best params
            model = self.train_single_model(
                model_name, train_data, val_data, best_params
            )

            # Evaluate performance
            performance = self.evaluate_model_performance(model, val_data)

            trained_models[model_name] = {
                "model": model,
                "params": best_params,
                "performance": performance
            }

            training_history[model_name] = {
                "training_time": model.training_time,
                "feature_importance": model.feature_importance,
                "validation_scores": model.validation_scores
            }

            print(f"   ‚úÖ {model_name} MAE: {performance['mae']:.4f}")

        # Train ensemble model
        print(f"   üéØ Training ensemble model...")
        ensemble_model = self.train_ensemble_model(trained_models, val_data)

        trained_models["ensemble"] = {
            "model": ensemble_model,
            "params": {"base_models": list(trained_models.keys())},
            "performance": self.evaluate_model_performance(ensemble_model, val_data)
        }

        return trained_models, training_history

    def hyperparameter_tuning(self, model_name, train_data, val_data, property_type):
        """
        Hyperparameter tuning v·ªõi Optuna
        """
        import optuna

        def objective(trial):
            # Generate hyperparameters based on model type
            if model_name == "xgboost":
                params = {
                    "n_estimators": trial.suggest_int("n_estimators", 100, 1000),
                    "max_depth": trial.suggest_int("max_depth", 3, 10),
                    "learning_rate": trial.suggest_float("learning_rate", 0.01, 0.3),
                    "subsample": trial.suggest_float("subsample", 0.6, 1.0),
                    "colsample_bytree": trial.suggest_float("colsample_bytree", 0.6, 1.0),
                }
            elif model_name == "lightgbm":
                params = {
                    "n_estimators": trial.suggest_int("n_estimators", 100, 1000),
                    "max_depth": trial.suggest_int("max_depth", 3, 10),
                    "learning_rate": trial.suggest_float("learning_rate", 0.01, 0.3),
                    "num_leaves": trial.suggest_int("num_leaves", 10, 100),
                    "feature_fraction": trial.suggest_float("feature_fraction", 0.6, 1.0),
                }
            elif model_name == "catboost":
                params = {
                    "iterations": trial.suggest_int("iterations", 100, 1000),
                    "depth": trial.suggest_int("depth", 4, 10),
                    "learning_rate": trial.suggest_float("learning_rate", 0.01, 0.3),
                    "l2_leaf_reg": trial.suggest_float("l2_leaf_reg", 1, 10),
                }

            # Train model with suggested params
            model = self.train_single_model(model_name, train_data, val_data, params)

            # Return validation MAE (minimize)
            val_predictions = model.predict(val_data)
            mae = mean_absolute_error(val_data["price"], val_predictions)

            return mae

        # Run optimization
        study = optuna.create_study(direction="minimize")
        study.optimize(objective, n_trials=50)

        return study.best_params

    def train_single_model(self, model_name, train_data, val_data, params):
        """
        Train m·ªôt model v·ªõi parameters c·ª• th·ªÉ
        """
        if model_name == "xgboost":
            import xgboost as xgb

            # Prepare data
            X_train = train_data.drop(["listing_id", "price"], axis=1)
            y_train = train_data["price"]
            X_val = val_data.drop(["listing_id", "price"], axis=1)
            y_val = val_data["price"]

            # Create model
            model = xgb.XGBRegressor(**params, random_state=42)

            # Train with early stopping
            model.fit(
                X_train, y_train,
                eval_set=[(X_val, y_val)],
                early_stopping_rounds=50,
                verbose=False
            )

        elif model_name == "lightgbm":
            import lightgbm as lgb

            X_train = train_data.drop(["listing_id", "price"], axis=1)
            y_train = train_data["price"]
            X_val = val_data.drop(["listing_id", "price"], axis=1)
            y_val = val_data["price"]

            model = lgb.LGBMRegressor(**params, random_state=42)
            model.fit(
                X_train, y_train,
                eval_set=[(X_val, y_val)],
                callbacks=[lgb.early_stopping(50)]
            )

        elif model_name == "catboost":
            from catboost import CatBoostRegressor

            X_train = train_data.drop(["listing_id", "price"], axis=1)
            y_train = train_data["price"]
            X_val = val_data.drop(["listing_id", "price"], axis=1)
            y_val = val_data["price"]

            model = CatBoostRegressor(**params, random_state=42, verbose=False)
            model.fit(
                X_train, y_train,
                eval_set=(X_val, y_val),
                early_stopping_rounds=50
            )

        return model

    def train_ensemble_model(self, base_models, val_data):
        """
        Train ensemble model t·ª´ base models
        """
        from sklearn.ensemble import VotingRegressor
        from sklearn.linear_model import Ridge

        # Get predictions from base models
        base_predictions = {}
        for model_name, model_info in base_models.items():
            predictions = model_info["model"].predict(val_data.drop(["listing_id", "price"], axis=1))
            base_predictions[model_name] = predictions

        # Create meta-features
        meta_features = pd.DataFrame(base_predictions)
        meta_target = val_data["price"]

        # Train meta-learner
        meta_learner = Ridge(alpha=1.0)
        meta_learner.fit(meta_features, meta_target)

        # Create ensemble model
        ensemble = EnsembleModel(base_models, meta_learner)

        return ensemble

class EnsembleModel:
    """
    Ensemble model wrapper
    """

    def __init__(self, base_models, meta_learner):
        self.base_models = base_models
        self.meta_learner = meta_learner

    def predict(self, X):
        # Get predictions from base models
        base_predictions = {}
        for model_name, model_info in self.base_models.items():
            predictions = model_info["model"].predict(X)
            base_predictions[model_name] = predictions

        # Create meta-features
        meta_features = pd.DataFrame(base_predictions)

        # Get final prediction from meta-learner
        final_predictions = self.meta_learner.predict(meta_features)

        return final_predictions
```

### üìä Training Monitoring & Logging

```python
class TrainingMonitor:
    """
    Monitor training progress v√† log metrics
    """

    def __init__(self, experiment_name):
        import mlflow
        self.experiment_name = experiment_name
        mlflow.set_experiment(experiment_name)

    def log_training_run(self, model_name, property_type, params, metrics, artifacts):
        """
        Log training run to MLflow
        """
        import mlflow

        with mlflow.start_run(run_name=f"{model_name}_{property_type}"):
            # Log parameters
            mlflow.log_params(params)

            # Log metrics
            mlflow.log_metrics(metrics)

            # Log model
            mlflow.sklearn.log_model(
                artifacts["model"],
                f"{model_name}_model"
            )

            # Log feature importance
            if "feature_importance" in artifacts:
                mlflow.log_artifact(artifacts["feature_importance"], "feature_importance.png")

            # Log training curves
            if "training_curves" in artifacts:
                mlflow.log_artifact(artifacts["training_curves"], "training_curves.png")

            # Log data drift reports
            if "data_drift_report" in artifacts:
                mlflow.log_artifact(artifacts["data_drift_report"], "data_drift_report.html")

    def create_training_dashboard(self, training_history):
        """
        T·∫°o dashboard theo d√µi training
        """
        import plotly.graph_objects as go
        from plotly.subplots import make_subplots

        fig = make_subplots(
            rows=2, cols=2,
            subplot_titles=("Training MAE", "Validation MAE", "Training Time", "Feature Importance"),
            specs=[[{"type": "scatter"}, {"type": "scatter"}],
                   [{"type": "bar"}, {"type": "bar"}]]
        )

        # Training/Validation MAE over time
        for model_name, history in training_history.items():
            fig.add_trace(
                go.Scatter(
                    x=list(range(len(history["train_mae"]))),
                    y=history["train_mae"],
                    name=f"{model_name}_train",
                    mode="lines"
                ),
                row=1, col=1
            )

            fig.add_trace(
                go.Scatter(
                    x=list(range(len(history["val_mae"]))),
                    y=history["val_mae"],
                    name=f"{model_name}_val",
                    mode="lines"
                ),
                row=1, col=2
            )

        # Training time comparison
        model_names = list(training_history.keys())
        training_times = [training_history[name]["training_time"] for name in model_names]

        fig.add_trace(
            go.Bar(x=model_names, y=training_times, name="Training Time"),
            row=2, col=1
        )

        fig.update_layout(
            title="Model Training Dashboard",
            height=800
        )

        return fig
```

---

## üìà B∆∞·ªõc 5: Model Evaluation & Selection (ƒê√°nh Gi√° & L·ª±a Ch·ªçn Model)

### üéØ Comprehensive Model Evaluation

```python
class ModelEvaluator:
    """
    ƒê√°nh gi√° to√†n di·ªán performance c·ªßa models
    """

    def __init__(self, config):
        self.config = config
        self.evaluation_metrics = [
            "mae", "rmse", "mape", "r2", "median_ae", "max_error"
        ]

    def evaluate_all_models(self, trained_models, test_data, property_type):
        """
        Evaluate t·∫•t c·∫£ trained models tr√™n test set
        """
        print(f"üìà Evaluating models for {property_type}...")

        evaluation_results = {}

        for model_name, model_info in trained_models.items():
            print(f"   üîç Evaluating {model_name}...")

            # Get predictions
            model = model_info["model"]
            X_test = test_data.drop(["listing_id", "price"], axis=1)
            y_test = test_data["price"]
            predictions = model.predict(X_test)

            # Calculate metrics
            metrics = self.calculate_comprehensive_metrics(y_test, predictions)

            # Price range analysis
            price_range_metrics = self.analyze_by_price_ranges(y_test, predictions)

            # Geographic analysis
            geographic_metrics = self.analyze_by_geography(
                test_data, predictions, property_type
            )

            # Temporal analysis
            temporal_metrics = self.analyze_by_time_periods(
                test_data, predictions
            )

            evaluation_results[model_name] = {
                "overall_metrics": metrics,
                "price_range_metrics": price_range_metrics,
                "geographic_metrics": geographic_metrics,
                "temporal_metrics": temporal_metrics,
                "predictions": predictions.tolist(),
                "residuals": (y_test - predictions).tolist()
            }

            print(f"   ‚úÖ {model_name} Results:")
            print(f"      MAE: {metrics['mae']:.4f}")
            print(f"      RMSE: {metrics['rmse']:.4f}")
            print(f"      MAPE: {metrics['mape']:.2f}%")
            print(f"      R¬≤: {metrics['r2']:.4f}")

        return evaluation_results

    def calculate_comprehensive_metrics(self, y_true, y_pred):
        """
        T√≠nh to√°n c√°c metrics ƒë√°nh gi√° comprehensive
        """
        from sklearn.metrics import (
            mean_absolute_error, mean_squared_error,
            r2_score, median_absolute_error, max_error
        )
        import numpy as np

        metrics = {
            "mae": mean_absolute_error(y_true, y_pred),
            "rmse": np.sqrt(mean_squared_error(y_true, y_pred)),
            "mape": np.mean(np.abs((y_true - y_pred) / y_true)) * 100,
            "r2": r2_score(y_true, y_pred),
            "median_ae": median_absolute_error(y_true, y_pred),
            "max_error": max_error(y_true, y_pred),

            # Business metrics
            "predictions_within_10pct": np.mean(np.abs((y_true - y_pred) / y_true) <= 0.1) * 100,
            "predictions_within_20pct": np.mean(np.abs((y_true - y_pred) / y_true) <= 0.2) * 100,

            # Bias metrics
            "mean_residual": np.mean(y_true - y_pred),
            "residual_std": np.std(y_true - y_pred),
        }

        return metrics

    def analyze_by_price_ranges(self, y_true, y_pred):
        """
        Ph√¢n t√≠ch performance theo t·ª´ng price range
        """
        import pandas as pd

        df = pd.DataFrame({
            "actual": y_true,
            "predicted": y_pred,
            "error": np.abs(y_true - y_pred),
            "error_pct": np.abs((y_true - y_pred) / y_true) * 100
        })

        # Define price ranges (in billions VND)
        price_ranges = [
            ("under_2b", 0, 2),      # D∆∞·ªõi 2 t·ª∑
            ("2b_to_5b", 2, 5),      # 2-5 t·ª∑
            ("5b_to_10b", 5, 10),    # 5-10 t·ª∑
            ("10b_to_20b", 10, 20),  # 10-20 t·ª∑
            ("over_20b", 20, 1000)   # Tr√™n 20 t·ª∑
        ]

        range_metrics = {}

        for range_name, min_price, max_price in price_ranges:
            mask = (df["actual"] >= min_price) & (df["actual"] < max_price)
            range_data = df[mask]

            if len(range_data) > 0:
                range_metrics[range_name] = {
                    "count": len(range_data),
                    "mae": range_data["error"].mean(),
                    "mape": range_data["error_pct"].mean(),
                    "within_10pct": (range_data["error_pct"] <= 10).mean() * 100,
                    "within_20pct": (range_data["error_pct"] <= 20).mean() * 100
                }
```
