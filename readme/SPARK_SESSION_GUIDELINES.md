# HÆ°á»›ng dáº«n thá»‘ng nháº¥t sá»­ dá»¥ng Spark Session

## ğŸ¯ **Quy táº¯c sá»­ dá»¥ng**

### âœ… **ETL Workflows â†’ `create_spark_session()`**

```python
from common.config.spark_config import create_spark_session

# âœ… ÄÃºng cho ETL: extraction, transformation, unification, load
spark = create_spark_session("ETL Job Name")
```

### âœ… **ML Workflows â†’ `create_optimized_ml_spark_session()`**

```python
from common.config.spark_config import create_optimized_ml_spark_session

# âœ… ÄÃºng cho ML: feature engineering, model training, inference
spark = create_optimized_ml_spark_session("ML Job Name")
```

## âŒ **Nhá»¯ng gÃ¬ KHÃ”NG Ä‘Æ°á»£c lÃ m**

### âŒ Tá»± táº¡o config riÃªng

```python
# âŒ SAI - KhÃ´ng tá»± táº¡o config
config = {
    "spark.sql.shuffle.partitions": "100",
    "spark.sql.adaptive.enabled": "true",
    # ... nhiá»u config khÃ¡c
}
spark = create_spark_session("Job Name", config=config)
```

### âŒ DÃ¹ng sai hÃ m cho workflow

```python
# âŒ SAI - DÃ¹ng ETL session cho ML
spark = create_spark_session("ML Job")  # Thiáº¿u tá»‘i Æ°u ML

# âŒ SAI - DÃ¹ng ML session cho ETL (overkill)
spark = create_optimized_ml_spark_session("ETL Job")  # Thá»«a tÃ i nguyÃªn
```

## ğŸ“‹ **Mapping workflow â†’ session type**

| Workflow Type | Function                              | Files                                                                                              |
| ------------- | ------------------------------------- | -------------------------------------------------------------------------------------------------- |
| **ETL**       | `create_spark_session()`              | `pipelines/daily_processing.py`<br>`jobs/extraction/*`<br>`jobs/transformation/*`<br>`jobs/load/*` |
| **ML**        | `create_optimized_ml_spark_session()` | `pipelines/ml_processing.py`<br>`jobs/enrichment/ml_*`<br>`ml/*`                                   |

## ğŸ”§ **ÄÃ£ tá»‘i Æ°u**

### âœ… Loáº¡i bá» code trÃ¹ng láº·p

-   XÃ³a config riÃªng láº» trong tá»«ng file
-   Centralized configuration trong `spark_config.py`
-   Thá»‘ng nháº¥t cÃ¡ch import vÃ  sá»­ dá»¥ng

### âœ… PhÃ¢n tÃ¡ch rÃµ rÃ ng

-   **ETL Session**: Memory = 2g/4g, Partitions = 50
-   **ML Session**: Memory = 3g/6g, Partitions = 100, Arrow enabled, ML optimizations

## ğŸš€ **Káº¿t quáº£**

-   **Consistency**: Táº¥t cáº£ files Ä‘á»u dÃ¹ng cÃ¹ng pattern
-   **Performance**: Má»—i workflow cÃ³ cáº¥u hÃ¬nh tá»‘i Æ°u riÃªng
-   **Maintainability**: Chá»‰ sá»­a 1 chá»— trong `spark_config.py`
-   **No Duplication**: KhÃ´ng cÃ²n config scattered kháº¯p nÆ¡i
