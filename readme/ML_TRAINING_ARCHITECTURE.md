# Ki·∫øn Tr√∫c ML Training Pipeline - Real Estate Project

## T·ªïng quan Lu·ªìng d·ªØ li·ªáu hi·ªán t·∫°i

```
Raw Data (Crawled) ‚Üí Bronze (Standardized) ‚Üí Silver (Cleaned) ‚Üí Gold (Unified)
```

## Thi·∫øt k·∫ø ML Pipeline Architecture

### 1. DATA FLOW ARCHITECTURE

```
Gold Data (HDFS)
    ‚Üì
Data Quality Validation
    ‚Üì
Feature Engineering Pipeline
    ‚Üì
Data Preparation & Splitting
    ‚Üì
Model Training Pipeline
    ‚Üì
Model Evaluation & Validation
    ‚Üì
Model Registry & Versioning
    ‚Üì
Model Deployment (Production)
```

### 2. CHI TI·∫æT C√ÅC T·∫¶NG X·∫¢L√ù

#### 2.1 GOLD DATA INPUT LAYER

**Ngu·ªìn:** `/hdfs/gold/realestate/{yyyy-mm-dd}/unified_properties.parquet`

**ƒê·∫∑c ƒëi·ªÉm Gold Data:**

-   ƒê√£ unified t·ª´ nhi·ªÅu ngu·ªìn (Batdongsan, Chotot, etc.)
-   C√≥ schema chu·∫©n h√≥a
-   ƒê√£ qua basic cleaning ·ªü Silver layer
-   Partitioned theo ng√†y

**Schema d·ª± ki·∫øn:**

```
unified_properties:
‚îú‚îÄ‚îÄ property_id: string
‚îú‚îÄ‚îÄ source: string (batdongsan/chotot)
‚îú‚îÄ‚îÄ title: string
‚îú‚îÄ‚îÄ price_cleaned: double
‚îú‚îÄ‚îÄ area_cleaned: double
‚îú‚îÄ‚îÄ bedrooms_cleaned: int
‚îú‚îÄ‚îÄ bathrooms_cleaned: int
‚îú‚îÄ‚îÄ city: string
‚îú‚îÄ‚îÄ district: string
‚îú‚îÄ‚îÄ property_type: string
‚îú‚îÄ‚îÄ description: string
‚îú‚îÄ‚îÄ latitude: double
‚îú‚îÄ‚îÄ longitude: double
‚îú‚îÄ‚îÄ crawl_date: date
‚îú‚îÄ‚îÄ quality_flags: struct
‚îî‚îÄ‚îÄ enrichment_data: struct
```

#### 2.2 DATA QUALITY VALIDATION LAYER

**M·ª•c ƒë√≠ch:** Ki·ªÉm tra ch·∫•t l∆∞·ª£ng data tr∆∞·ªõc khi train

**C√°c ki·ªÉm tra:**

-   **Completeness:** % missing values cho features quan tr·ªçng
-   **Validity:** Range checks (price > 0, area > 0, etc.)
-   **Consistency:** Cross-field validation
-   **Freshness:** Data recency checks
-   **Distribution:** Statistical outlier detection

**Output:**

-   Quality report
-   Filtered dataset (ch·ªâ data ƒë·∫°t quality threshold)

#### 2.3 FEATURE ENGINEERING PIPELINE

**M·ª•c ƒë√≠ch:** T·∫°o features phong ph√∫ t·ª´ raw Gold data

**Feature Categories:**

**A. Numeric Features:**

-   `price_log`: log transformation of price
-   `area_log`: log transformation of area
-   `price_per_sqm`: price density
-   `price_per_bedroom`: room value metric
-   `bedroom_bathroom_ratio`: layout efficiency

**B. Temporal Features:**

-   `year`, `month`, `quarter`, `season`: time components
-   `days_since_crawl`: recency metric
-   `is_weekend`: timing feature

**C. Location Features:**

-   `city_district`: combined location
-   `location_price_rank`: price ranking by location
-   `distance_to_center`: proximity feature (if coordinates available)

**D. Market Features:**

-   `avg_price_by_location`: local market average
-   `price_deviation_from_market`: relative positioning
-   `supply_density`: properties count by area
-   `price_volatility`: local price variance

**E. Quality Features:**

-   `data_completeness_score`: data quality metric
-   `source_reliability`: source-based scoring
-   `description_richness`: text content quality

**F. Interaction Features:**

-   `area_location_interaction`: size-location combination
-   `price_segment`: high/medium/low by location

#### 2.4 DATA PREPARATION LAYER

**M·ª•c ƒë√≠ch:** Chu·∫©n b·ªã data cho training

**C√°c b∆∞·ªõc:**

**A. Feature Selection:**

-   Correlation analysis
-   Feature importance ranking
-   Multicollinearity detection
-   Business logic filtering

**B. Data Splitting Strategy:**

```
Training Set (70%): Oldest data ‚Üí Recent-2months
Validation Set (15%): Recent-2months ‚Üí Recent-1month
Test Set (15%): Recent-1month ‚Üí Latest
```

**C. Data Preprocessing:**

-   Categorical encoding (One-hot/Label encoding)
-   Numerical scaling (StandardScaler/MinMaxScaler)
-   Missing value imputation
-   Outlier treatment

#### 2.5 MODEL TRAINING PIPELINE

**M·ª•c ƒë√≠ch:** Train multiple model variants v√† ch·ªçn best model

**A. Model Types:**

```
Primary Models:
‚îú‚îÄ‚îÄ RandomForestRegressor
‚îú‚îÄ‚îÄ GradientBoostingRegressor
‚îú‚îÄ‚îÄ XGBoostRegressor
‚îî‚îÄ‚îÄ LightGBMRegressor

Advanced Models:
‚îú‚îÄ‚îÄ CatBoostRegressor
‚îú‚îÄ‚îÄ ExtraTreesRegressor
‚îî‚îÄ‚îÄ ElasticNet (baseline)
```

**B. Hyperparameter Tuning:**

-   Grid Search cho baseline models
-   Random Search cho complex models
-   Bayesian Optimization cho production models
-   Cross-validation v·ªõi time-series split

**C. Training Strategy:**

```
For each model type:
1. Baseline training v·ªõi default params
2. Hyperparameter tuning
3. Feature selection optimization
4. Cross-validation evaluation
5. Final model training v·ªõi best params
```

#### 2.6 MODEL EVALUATION LAYER

**M·ª•c ƒë√≠ch:** Comprehensive model assessment

**A. Performance Metrics:**

-   **Primary:** RMSE, MAE, MAPE
-   **Business:** Accuracy within 10%/20% range
-   **Statistical:** R¬≤, Adjusted R¬≤
-   **Robustness:** Performance by price segments

**B. Validation Tests:**

-   **Temporal validation:** Recent data performance
-   **Geographical validation:** Performance by location
-   **Segment validation:** Performance by property type
-   **Outlier robustness:** Performance on edge cases

**C. Model Comparison:**

-   Performance ranking
-   Training time analysis
-   Memory usage assessment
-   Inference speed testing

#### 2.7 MODEL REGISTRY & VERSIONING

**M·ª•c ƒë√≠ch:** Qu·∫£n l√Ω model lifecycle

**A. Model Metadata:**

```
model_version:
‚îú‚îÄ‚îÄ model_id: unique identifier
‚îú‚îÄ‚îÄ training_date: when trained
‚îú‚îÄ‚îÄ data_period: data range used
‚îú‚îÄ‚îÄ features_used: feature list
‚îú‚îÄ‚îÄ hyperparameters: model config
‚îú‚îÄ‚îÄ performance_metrics: evaluation results
‚îú‚îÄ‚îÄ training_duration: time taken
‚îî‚îÄ‚îÄ data_quality_score: input data quality
```

**B. Versioning Strategy:**

-   **Major version:** Algorithm change
-   **Minor version:** Feature engineering change
-   **Patch version:** Hyperparameter tuning

**C. Model Stages:**

-   `development`: newly trained
-   `staging`: passed validation
-   `production`: serving traffic
-   `archived`: retired

#### 2.8 MODEL DEPLOYMENT LAYER

**M·ª•c ƒë√≠ch:** Deploy model v√†o production

**A. Deployment Options:**

-   **Batch Prediction:** Daily price estimates
-   **Real-time API:** On-demand predictions
-   **Streaming:** Live property analysis

**B. A/B Testing:**

-   Champion vs Challenger comparison
-   Traffic splitting
-   Performance monitoring

### 3. PIPELINE ORCHESTRATION

#### 3.1 AIRFLOW DAG ARCHITECTURE

```
ml_training_pipeline_dag:
‚îú‚îÄ‚îÄ validate_gold_data (30 min)
‚îú‚îÄ‚îÄ run_feature_engineering (60 min)
‚îú‚îÄ‚îÄ prepare_training_data (20 min)
‚îú‚îÄ‚îÄ train_models_parallel (120 min)
‚îÇ   ‚îú‚îÄ‚îÄ train_random_forest
‚îÇ   ‚îú‚îÄ‚îÄ train_gradient_boosting
‚îÇ   ‚îú‚îÄ‚îÄ train_xgboost
‚îÇ   ‚îî‚îÄ‚îÄ train_lightgbm
‚îú‚îÄ‚îÄ evaluate_models (30 min)
‚îú‚îÄ‚îÄ select_best_model (10 min)
‚îú‚îÄ‚îÄ register_model (10 min)
‚îî‚îÄ‚îÄ deploy_to_staging (20 min)
```

#### 3.2 SCHEDULING STRATEGY

```
Daily Training (Incremental):
- Trigger: After Gold data ready (daily_processing_dag completes)
- Frequency: Daily at 6:00 AM
- Training data: Last 30 days rolling window

Weekly Full Retraining:
- Trigger: Sunday 2:00 AM
- Frequency: Weekly
- Training data: Last 90 days full dataset

Monthly Model Refresh:
- Trigger: 1st day of month, 4:00 AM
- Frequency: Monthly
- Training data: Last 180 days + hyperparameter retuning
```

### 4. DATA STORAGE ARCHITECTURE

#### 4.1 HDFS Structure

```
/hdfs/ml_pipeline/
‚îú‚îÄ‚îÄ features/
‚îÇ   ‚îú‚îÄ‚îÄ {yyyy-mm-dd}/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ raw_features.parquet
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ engineered_features.parquet
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ final_features.parquet
‚îú‚îÄ‚îÄ datasets/
‚îÇ   ‚îú‚îÄ‚îÄ {yyyy-mm-dd}/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train.parquet
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ validation.parquet
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test.parquet
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ {model_version}/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model_artifacts/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ feature_pipeline/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ metadata.json
‚îî‚îÄ‚îÄ evaluations/
    ‚îú‚îÄ‚îÄ {model_version}/
    ‚îÇ   ‚îú‚îÄ‚îÄ metrics.json
    ‚îÇ   ‚îú‚îÄ‚îÄ validation_report.html
    ‚îî‚îÄ‚îÄ ‚îî‚îÄ‚îÄ feature_importance.csv
```

#### 4.2 Model Registry Storage

```
/models/registry/
‚îú‚îÄ‚îÄ price_prediction/
‚îÇ   ‚îú‚îÄ‚îÄ v1.0.0_20250605/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ metadata.json
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ metrics.json
‚îÇ   ‚îú‚îÄ‚îÄ v1.1.0_20250612/
‚îÇ   ‚îî‚îÄ‚îÄ production -> v1.0.0_20250605/
```

### 5. MONITORING & ALERTING

#### 5.1 Data Quality Monitoring

-   Missing value trends
-   Distribution drift detection
-   Outlier frequency tracking
-   Source data availability

#### 5.2 Model Performance Monitoring

-   Prediction accuracy trends
-   Error distribution analysis
-   Feature importance changes
-   Inference latency tracking

#### 5.3 Pipeline Health Monitoring

-   Training job success rates
-   Resource utilization
-   Processing time trends
-   Error rate tracking

### 6. CONFIGURATION MANAGEMENT

#### 6.1 Environment Configuration

```
environments:
‚îú‚îÄ‚îÄ development: Local testing
‚îú‚îÄ‚îÄ staging: UAT environment
‚îú‚îÄ‚îÄ production: Live serving
```

#### 6.2 Feature Configuration

```yaml
feature_engineering:
    price_features:
        - price_log: true
        - price_per_sqm: true
        - price_percentile: true

    temporal_features:
        - season: true
        - month: true
        - days_since_crawl: true

    market_features:
        - local_average: true
        - price_deviation: true
        - supply_density: true
```

#### 6.3 Model Configuration

```yaml
models:
    random_forest:
        enabled: true
        n_estimators: [100, 200, 300]
        max_depth: [10, 15, 20]

    xgboost:
        enabled: true
        learning_rate: [0.01, 0.1, 0.2]
        max_depth: [6, 8, 10]
```

## NEXT STEPS - IMPLEMENTATION PLAN

### Phase 1: Foundation (Week 1-2)

1. ‚úÖ Clean up existing ML code
2. üîÑ Implement data quality validation
3. üîÑ Enhanced feature engineering pipeline
4. üîÑ Data preparation utilities

### Phase 2: Core Training (Week 3-4)

1. Enhanced model training pipeline
2. Model evaluation framework
3. Model registry integration
4. Basic Airflow DAG

### Phase 3: Production Ready (Week 5-6)

1. Advanced model comparison
2. A/B testing framework
3. Monitoring & alerting
4. Full deployment pipeline

### Phase 4: Optimization (Week 7-8)

1. Hyperparameter optimization
2. Feature selection automation
3. Performance optimization
4. Advanced monitoring

---

**C√¢u h·ªèi cho b·∫°n:**

1. Ki·∫øn tr√∫c n√†y c√≥ ph√π h·ª£p v·ªõi workflow hi·ªán t·∫°i kh√¥ng?
2. C√≥ feature n√†o b·∫°n mu·ªën th√™m/b·ªõt kh√¥ng?
3. T·∫ßn su·∫•t training (daily/weekly) c√≥ h·ª£p l√Ω kh√¥ng?
4. C·∫ßn ∆∞u ti√™n implement ph·∫ßn n√†o tr∆∞·ªõc?
