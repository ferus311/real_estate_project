from pyspark.sql import SparkSession

# Táº¡o Spark session
spark = SparkSession.builder \
    .appName("Preview HDFS Data") \
    .getOrCreate()

# ÄÆ°á»ng dáº«n file HTML crawl lÆ°u trÃªn HDFS
input_path = "hdfs://namenode:9000/raw/example.html"

try:
    # Äá»c file HTML dÆ°á»›i dáº¡ng vÄƒn báº£n
    rdd = spark.sparkContext.textFile(input_path)
    print("ğŸ“„ Ná»™i dung file HTML:")
    for line in rdd.take(20):  # Hiá»ƒn thá»‹ 20 dÃ²ng Ä‘áº§u tiÃªn
        print(line)

except Exception as e:
    print(f"âŒ Lá»—i khi Ä‘á»c dá»¯ liá»‡u tá»« HDFS: {e}")
finally:
    spark.stop()
